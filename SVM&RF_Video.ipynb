{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/notmanan/Depression-Detection-Through-Multi-Modal-Data/blob/master/SVM%26RF_Video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ncPer7MulwaY"
      },
      "source": [
        "**Connecting Drive to Google Colab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "colab_type": "code",
        "id": "4FkprWXdn7N3",
        "outputId": "1c03e054-521b-4fa7-de05-b7ed552c57f5"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J9ZapOLwl70D"
      },
      "source": [
        "# Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Dzxb5JsroQ5y"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/MCA Dataset/dev_split_Depression_AVEC2017.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 37\u001b[0m\n\u001b[0;32m     33\u001b[0m     X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((X1, X2, X3, X4, X6), \u001b[39m1\u001b[39m)\n\u001b[0;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m X\n\u001b[1;32m---> 37\u001b[0m dataset1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m/content/drive/My Drive/MCA Dataset/dev_split_Depression_AVEC2017.csv\u001b[39;49m\u001b[39m'\u001b[39;49m,delimiter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m,encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m))[:, \u001b[39m0\u001b[39m:\u001b[39m2\u001b[39m]\n\u001b[0;32m     38\u001b[0m dataset2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m/content/drive/My Drive/MCA Dataset/full_test_split.csv\u001b[39m\u001b[39m'\u001b[39m,delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m,encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))[:, \u001b[39m0\u001b[39m:\u001b[39m2\u001b[39m]\n\u001b[0;32m     39\u001b[0m dataset3 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m/content/drive/My Drive/MCA Dataset/train_split_Depression_AVEC2017.csv\u001b[39m\u001b[39m'\u001b[39m,delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m,encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))[:, \u001b[39m0\u001b[39m:\u001b[39m2\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\prath\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[1;32mc:\\Users\\prath\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Users\\prath\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
            "File \u001b[1;32mc:\\Users\\prath\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Users\\prath\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[0;32m    869\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[0;32m    871\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/MCA Dataset/dev_split_Depression_AVEC2017.csv'"
          ]
        }
      ],
      "source": [
        "def processData(data):\n",
        "    # print(data)\n",
        "    X = data.iloc[:,:].values\n",
        "    X = np.delete(X, 0, 1)\n",
        "    X = np.delete(X, 1, 1)\n",
        "    X = np.mean(X, 0)\n",
        "    X = np.array(X.reshape(1, -1))\n",
        "    # print(X)\n",
        "    # print(X.shape)\n",
        "    return X\n",
        "\n",
        "def getData(filename):\n",
        "    # print(filename)\n",
        "    data = pd.read_csv(filename,delimiter=',')\n",
        "    X = processData(data)\n",
        "    return X\n",
        "\n",
        "def makeDataPoint(patientNo):\n",
        "    file1 = (patientNo)+\"_CLNF_AUs.txt\"\n",
        "    file2 = (patientNo)+\"_CLNF_features.txt\"\n",
        "    file3 = (patientNo)+\"_CLNF_features3D.txt\"\n",
        "    file4 = (patientNo)+\"_CLNF_gaze.txt\"\n",
        "    file5 = (patientNo)+\"_CLNF_hog.txt\"\n",
        "    file6 = (patientNo)+\"_CLNF_pose.txt\"\n",
        "\n",
        "    X1 = getData(file1)\n",
        "    X2 = getData(file2)\n",
        "    X3 = getData(file3)\n",
        "    X4 = getData(file4)\n",
        "    # X5 = getData(file5)\n",
        "    X6 = getData(file6)\n",
        "\n",
        "    X = np.concatenate((X1, X2, X3, X4, X6), 1)\n",
        "    return X\n",
        "\n",
        "\n",
        "dataset1 = np.array(pd.read_csv('/content/drive/My Drive/MCA Dataset/dev_split_Depression_AVEC2017.csv',delimiter=',',encoding='utf-8'))[:, 0:2]\n",
        "dataset2 = np.array(pd.read_csv('/content/drive/My Drive/MCA Dataset/full_test_split.csv',delimiter=',',encoding='utf-8'))[:, 0:2]\n",
        "dataset3 = np.array(pd.read_csv('/content/drive/My Drive/MCA Dataset/train_split_Depression_AVEC2017.csv',delimiter=',',encoding='utf-8'))[:, 0:2]\n",
        "\n",
        "dataset = np.concatenate((dataset1, np.concatenate((dataset2, dataset3))))\n",
        "positive = []\n",
        "negative = []\n",
        "\n",
        "for i in range(len(dataset)):\n",
        "    if dataset[i][0]<=310 and dataset[i][0]>=300:\n",
        "        if(dataset[i][1] == 0):\n",
        "            positive.append(int(dataset[i][0]))\n",
        "        else:\n",
        "            negative.append(int(dataset[i][0]))\n",
        "\n",
        "    elif dataset[i][0]<=355 and dataset[i][0]>=345:\n",
        "        if(dataset[i][1] == 0):\n",
        "            positive.append(int(dataset[i][0]))\n",
        "        else:\n",
        "            negative.append(int(dataset[i][0]))\n",
        "\n",
        "X = np.zeros((1,388))\n",
        "for i in positive:\n",
        "    string = '/content/drive/My Drive/MCA Dataset/positive_data/'+str(i)\n",
        "    X_temp = makeDataPoint(string)\n",
        "    X = np.concatenate((X,X_temp),0)\n",
        "Y = np.zeros((len(positive),1))\n",
        "for i in negative:\n",
        "    string = '/content/drive/My Drive/MCA Dataset/negative_data/'+str(i)\n",
        "    X_temp = makeDataPoint(string)\n",
        "    X = np.concatenate((X,X_temp),0)\n",
        "Y = np.concatenate((Y,np.ones((len(negative),1))),0)\n",
        "X = np.delete(X,0,0)\n",
        "\n",
        "# print(\"train\")\n",
        "X_train, Y_train = makeDataset('/content/drive/My Drive/MCA Dataset/train_split_Depression_AVEC2017.csv', 'train_data')\n",
        "# print(\"dev\")\n",
        "X_dev, Y_dev = makeDataset('/content/drive/My Drive/MCA Dataset/dev_split_Depression_AVEC2017.csv', 'dev_data')\n",
        "count0 = 0\n",
        "X_train = np.concatenate((X_train, X_dev), 0  )\n",
        "Y_train = np.concatenate((Y_train, Y_dev), 0  )\n",
        "\n",
        "# print(\"test\")\n",
        "X_test, Y_test = makeDataset('/content/drive/My Drive/MCA Dataset/full_test_split.csv', 'test_data')\n",
        "# print(Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "padperlL6-ri"
      },
      "source": [
        "**RF and SVM on dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ClUVyIzMXre8"
      },
      "outputs": [],
      "source": [
        "\n",
        "clf1 = RandomForestClassifier()\n",
        "clf1.fit(X_train,Y_train)\n",
        "clf1.predict(X_test)\n",
        "print(\"Random forest: \"+ str(clf1.score(X_test,Y_test)))\n",
        "\n",
        "\n",
        "classifier2 = SVC(kernel = 'rbf', random_state = 0)\n",
        "classifier2.fit(X_train, Y_train)\n",
        "classifier2.predict(X_test)\n",
        "print(\"SVM rbf: \"+ str(classifier2.score(X_test,Y_test)))\n",
        "\n",
        "clf1.predict(X_train)\n",
        "print(\"Random forest: train\"+ str(clf1.score(X_train,Y_train)))\n",
        "\n",
        "classifier2.predict(X_train)\n",
        "print(\"SVM: train  \"+ str(classifier2.score(X_train,Y_train)))\n",
        "\n",
        "\n",
        "y_pred = classifier2.predict(X_test)\n",
        "print(classification_report(Y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "40NgARfxnKZF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random forest: \n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRandom forest: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m rfModel \u001b[39m=\u001b[39m RfVideo()\n\u001b[1;32m---> 29\u001b[0m rfModel\u001b[39m.\u001b[39mfitModel(X_train, Y_train)\n\u001b[0;32m     30\u001b[0m Y_pred1  \u001b[39m=\u001b[39m rfModel\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     31\u001b[0m \u001b[39mprint\u001b[39m(classification_report(Y_test, Y_pred1))\n",
            "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "class RfVideo:\n",
        "  def __init__(self):\n",
        "    self.classifier = RandomForestClassifier()\n",
        "  \n",
        "  def fitModel(self, X, Y):\n",
        "    self.classfier.fit(X, Y)\n",
        "  \n",
        "  def predictModel(self, X):\n",
        "    return self.classifier.predict(X)\n",
        "  \n",
        "  def scoreModel(self, X, Y):\n",
        "    return self.classifier.score(X, Y)\n",
        "\n",
        "class SVMVideo:\n",
        "  def __init__(self, kernel = \"rbf\"):\n",
        "    self.classifier = SVC(kernel = kernel, random_state = 0)\n",
        "  \n",
        "  def fitModel(self, X, Y):\n",
        "    self.classfier.fit(X, Y)\n",
        "  \n",
        "  def predictModel(self, X):\n",
        "    return self.classifier.predict(X)\n",
        "  \n",
        "  def scoreModel(self, X, Y):\n",
        "    return self.classifier.score(X, Y)\n",
        "\n",
        "print(\"Random forest: \")\n",
        "rfModel = RfVideo()\n",
        "rfModel.fitModel(X_train, Y_train)\n",
        "Y_pred1  = rfModel.predict(X_test)\n",
        "print(classification_report(Y_test, Y_pred1))\n",
        "\n",
        "print(\"SVM: \")\n",
        "svmModel = SVMVideo()\n",
        "svmModel.fitModel(X_train, Y_train)\n",
        "Y_pred2  = svmModel.predict(X_test)\n",
        "print(classification_report(Y_test, Y_pred2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "SVM&RF_Video.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
